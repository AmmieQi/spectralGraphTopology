---
title: "Learning the topology of graphs"
author: "Convex Group-HKUST"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
  bookdown::html_document2:
    base_format: prettydoc::html_pretty
    theme: tactile
    highlight: vignette
    fig_caption: yes
    number_sections: no
    toc: yes
    toc_depth: 2
header-includes:
  \allowdisplaybreaks
indent: yes
csl: ieee.csl
bibliography: refs.bib
vignette: >
  %\VignetteIndexEntry{Learning the topology of graphs}
  %\VignetteKeyword{graph, topology, clustering}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, echo = FALSE}
library(knitr)
opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.retina = 2,
  out.width = "75%",
  dpi = 96
)
knit_hooks$set(pngquant = hook_pngquant)
#Help on bookdown: https://bookdown.org/yihui/bookdown/
#rmarkdown::render("vignettes/SpectralGraphTopology-vignette.Rmd", "all")
#rmarkdown::render("vignettes/SpectralGraphTopology-vignette.Rmd", "bookdown::html_document2")
#rmarkdown::render("vignettes/SpectralGraphTopology-vignette.Rmd", "bookdown::pdf_document2")
#tools::compactPDF("vignettes/SpectralGraphTopology-vignette.pdf", gs_quality = "ebook")
```

-----------


# Comparison with other packages

# Usage of the package
We illustrate the usage of the package with simulated data, as follows.
```{r, cache = TRUE}
library(spectralGraphTopology)
set.seed(123)

# Number of samples
T <- 10000
# Vector to generate the Laplacian matrix of the graph
w <- runif(10)
# Laplacian matrix
Theta <- L(w)
# Sample data from a Multivariate Gaussian
N <- ncol(Theta)
Y <- MASS::mvrnorm(T, rep(0, N), MASS::ginv(Theta))
# Number of components of the graph
K <- 1
# Learn the Laplacian matrix
Theta_est <- learnGraphTopology(Y, K)
```

We can evaluate the performance of the learning process by computing
the relative error between the true Laplacian matrix and the estimated one,
which can be done as follows

```{r}
RE <- norm(Theta - Theta_est, type="F") / max(1., norm(Theta, type="F"))
RE
#> [1]
```

For K > 1, we can generate the Laplacian as a block diagonal matrix, as follows
```{r}
w1 <- runif(10)
w2 <- runif(6)
Theta1 <- L(w1)
Theta2 <- L(w2)
N1 <- ncol(Theta1)
N2 <- ncol(Theta2)
Theta <- rbind(cbind(Theta1, matrix(0, N1, N2)),
               cbind(matrix(0, N2, N1)), Theta2)
Y <- MASS::mvrnorm(T, rep(0, N1 + N2), MASS::ginv(Theta))
K <- 2
Theta_est <- learnGraphTopology(Y, K)
RE <- norm(Theta - Theta_est, type="F") / max(1., norm(Theta, type="F"))
RE
```

# Explanation of the algorithms

## `learnGraphTopology`: Learning the topology of graph

The goal of `learnGraphTopology()` is to estimate the Laplacian matrix generated
by the weight vector of a graph, $\mathbf{w}$.

> **Algorithm 1**

  1. Choose initial values for $\mathbf{w}$, $\mathbf{U}$, $\boldsymbol{\Lambda}$,
     and $\beta$, and compute $\mathcal{L}\mathbf{w}^{(0)}$
  2. Define the number of components $K$ and tunning parameters, $\alpha$, $\alpha_1$, $\alpha_2$, $\rho$
  3. Set $j=0$, while not converged do
  4. Set $i=0$, while not converged do
  5. Update $\mathbf{w}$, $\mathbf{w}^{(i+1)} \gets f_{\mathbf{w}}(\mathbf{w}^{(i)}, \mathbf{U}^{(i)}, \boldsymbol{\Lambda}^{(i)}, \beta, n, \mathbf{K})$
  6. Update $\mathbf{U}$, $\mathbf{U}^{(i+1)} \gets f_{\mathbf{U}}(\mathbf{w}^{(i+1)}, n, K)$
  7. Update $\boldsymbol{\Lambda}$, $\boldsymbol{\Lambda}^{(i+1)} \gets f_{\boldsymbol{\Lambda}}(\alpha_1, \alpha_2, \beta, \mathbf{w}^{(i+1)}, \mathbf{U}^{(i+1)}, n, K)$
  8. $i \gets i+1$
  9. $\beta \gets \beta(\rho + 1)$
  10. Repeat steps $4-9$ until convergence
  11. Compute $\mathcal{L}\mathbf{w}^{(i)}$
  12. $j \gets j+1$
  13. Repeat steps $3-12$ until convergence
  14. Return $\mathcal{L}\mathbf{w}^{(i)}$

# References {-}
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent
